<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Can we use AI to discover better algorithms? | Richard Cornelius Suwandi </title> <meta name="author" content="Richard Cornelius Suwandi"> <meta name="description" content="A review of FunSearch and AlphaEvolve"> <meta name="keywords" content="academic, personal, phd, richard cornelius suwandi, cuhk, cuhksz, machine learning, artificial intelligence, data science, bayesian optimization"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="preconnect" href="https://fonts.googleapis.com"> <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&amp;display=swap" rel="stylesheet"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700;900&amp;family=Open+Sans:ital,wght@0,300;0,400;0,600;0,700;1,300;1,400;1,600;1,700&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/icon_dark.PNG?14ecb2d6d14ba0d3c8d0e1f2823062e2"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://richardcsuwandi.github.io/blog/2025/llm-algorithm-discovery/"> <script src="/assets/js/theme.js?45472a5b6e0e229b5005be907f3fe1ac"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> <style type="text/css">.center{display:block;margin-left:auto;margin-right:auto}.framed{border:1px var(--global-text-color) dashed!important;padding:20px}d-article{overflow-x:visible}.underline{text-decoration:underline}.todo{display:block;margin:12px 0;font-style:italic;color:red}.todo:before{content:"TODO: ";font-weight:bold;font-style:normal}summary{color:steelblue;font-weight:bold}summary-math{text-align:center;color:black}[data-theme="dark"] summary-math{text-align:center;color:white}details[open]{--bg:#e2edfc;color:black;border-radius:15px;padding-left:8px;background:var(--bg);outline:.5rem solid var(--bg);margin:0 0 2rem 0;font-size:80%;line-height:1.4}[data-theme="dark"] details[open]{--bg:#112f4a;color:white;border-radius:15px;padding-left:8px;background:var(--bg);outline:.5rem solid var(--bg);margin:0 0 2rem 0;font-size:80%}.box-note,.box-warning,.box-error,.box-important{padding:15px 15px 15px 10px;margin:20px 20px 20px 5px;border:1px solid #eee;border-left-width:5px;border-radius:5px 3px 3px 5px}d-article .box-note{background-color:#eee;border-left-color:#3498db}d-article .box-warning{background-color:#eee;border-left-color:#ffc107}d-article .box-error{background-color:#eee;border-left-color:#dc3545}d-article .box-important{background-color:#eee;border-left-color:#20c997}html[data-theme='dark'] d-article .box-note{background-color:#2f2f2f;border-left-color:#3498db}html[data-theme='dark'] d-article .box-warning{background-color:#2f2f2f;border-left-color:#ffc107}html[data-theme='dark'] d-article .box-error{background-color:#2f2f2f;border-left-color:#dc3545}html[data-theme='dark'] d-article .box-important{background-color:#2f2f2f;border-left-color:#20c997}d-article aside{border:1px solid #aaa;border-radius:4px;padding:.5em .5em 0;font-size:90%}.caption{font-size:80%;line-height:1.2;text-align:left}d-citation-list .references .title{margin-bottom:-5px;line-height:1.3}d-citation-list .references .authors{margin-top:-5px;line-height:1.3}d-citation-list .references{line-height:1.3}</style> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Can we use AI to discover better algorithms?",
            "description": "A review of FunSearch and AlphaEvolve",
            "published": "May 15, 2025",
            "authors": [
              
              {
                "author": "Richard Cornelius Suwandi",
                "authorURL": "https://richardcsuwandi.github.io/",
                "affiliations": [
                  {
                    "name": "The Chinese University of Hong Kong, Shenzhen",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <div class="navbar-brand social"> <a href="mailto:%72%69%63%68%61%72%64%73%75%77%61%6E%64%69@%6C%69%6E%6B.%63%75%68%6B.%65%64%75.%63%6E" title="email" class="social-icon" style="margin-right: 15px;"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=28o0CkgAAAAJ" title="Google Scholar" class="social-icon" style="margin-right: 15px;" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/richardcsuwandi" title="GitHub" class="social-icon" style="margin-right: 15px;" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/richardcsuwandi" title="LinkedIn" class="social-icon" style="margin-right: 15px;" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://twitter.com/richardcsuwandi" title="X" class="social-icon" style="margin-right: 15px;" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/assets/pdf/cv.pdf">CV </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Can we use AI to discover better algorithms?</h1> <p>A review of FunSearch and AlphaEvolve</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#introduction">Introduction</a> </div> <div> <a href="#funsearch">FunSearch</a> </div> <ul> <li> <a href="#how-funsearch-works">How FunSearch Works</a> </li> <li> <a href="#benefits-of-funsearch">Benefits of FunSearch</a> </li> </ul> <div> <a href="#alphaevolve">AlphaEvolve</a> </div> <ul> <li> <a href="#how-alphaevolve-works">How AlphaEvolve Works</a> </li> <li> <a href="#benefits-of-alphaevolve">Benefits of AlphaEvolve</a> </li> </ul> <div> <a href="#funsearch-vs-alphaevolve">FunSearch vs AlphaEvolve</a> </div> <div> <a href="#takeaways">Takeaways</a> </div> </nav> </d-contents> <p>Large language models (LLMs) have rapidly become indispensable AI assistants. They excel at synthesizing concepts, writing, and coding to help humans solve complex problems<d-cite key="chen2021evaluating"></d-cite> . But could they discover entirely new knowledge? As LLMs have been shown to “hallucinate”<d-cite key="farquhar2024detecting"></d-cite> factually incorrect information, using them to make verifiably correct discoveries is a challenge. But what if we could harness the creativity of LLMs by identifying and building upon only their very best ideas? This question is at the heart of recent breakthroughs from <a href="https://deepmind.google/" rel="external nofollow noopener" target="_blank">Google DeepMind</a>, which explore how LLMs can be guided to make novel discoveries in mathematics and algorithm design. This post delves into two pioneering works, FunSearch and the more recent AlphaEvolve, showcasing their approaches and implications for the future of automated algorithm discovery.</p> <h2 id="funsearch">FunSearch</h2> <p>In a paper published in Nature<d-cite key="romera2024mathematical"></d-cite>, Google DeepMind introduced <a href="https://deepmind.google/discover/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/" rel="external nofollow noopener" target="_blank">FunSearch</a>, a groundbreaking method demonstrating that LLMs can make new discoveries in mathematical sciences. The core idea is to search for novel “functions” written in computer code, hence the name FunSearch. FunSearch tackles the trade-off between LLMs’ creativity and correctness by pairing a pre-trained LLM with an automated “evaluator.” This evaluator guards against hallucinations and incorrect ideas, ensuring that the system builds upon solid foundations.</p> <h3 id="how-funsearch-works">How FunSearch works</h3> <p><img src="/assets/img/funsearch.png" alt="Overview of FunSearch" class="l-body rounded z-depth-1 center" width="80%"></p> <div class="l-gutter caption"> <p><strong>Figure 1.</strong> The FunSearch process. The LLM is shown a selection of the best programs it has generated so far, and asked to generate an even better one. The programs proposed by the LLM are automatically executed, and evaluated. The best programs are added to the database, for selection in subsequent cycles.</p> </div> <p>FunSearch uses an evolutionary approach<d-cite key="mouret2015illuminating"></d-cite><d-cite key="tanese1989distributed"></d-cite>. To start, the user writes a description of the problem in code. This includes a way to evaluate programs and an initial “seed” program to begin the process. The system then follows these steps:</p> <ol> <li>It selects the most promising programs from the current database.</li> <li>These programs are sent to an LLM<d-footnote>In their work, Google's PaLM 2 was used, though other code-trained LLMs can also work.</d-footnote>, which creatively builds upon them to generate new program proposals.</li> <li>The new programs are automatically run and checked by the evaluator.</li> <li>The best-performing valid programs are added back into the database, improving the database for the next round.</li> </ol> <aside class="l-body box-note"> <p>This cycle of selection, generation, evaluation, and update creates a <em>self-improving loop</em>. Starting from basic knowledge about the problem and using strategies to keep the database diverse, FunSearch is able to evolve simple solutions into more advanced ones. It can solve complex problems where human intuition might fall short.</p> </aside> <h3 id="benefits-of-funsearch">Benefits of FunSearch</h3> <p>FunSearch’s capabilities were tested on challenging problems. For example, it was used to solve the <strong><a href="https://en.wikipedia.org/wiki/Cap_set" rel="external nofollow noopener" target="_blank">cap set problem</a></strong>, which involves finding the largest set of points in a high-dimensional grid where no three points lie on a line. This longstanding open problem in extremal combinatorics, once described by renowned mathematician Terence Tao as his <a href="https://terrytao.wordpress.com/2007/02/23/open-question-best-bounds-for-cap-sets/" rel="external nofollow noopener" target="_blank">favorite open question</a>, was solved by FunSearch, in collaboration with <a href="https://people.math.wisc.edu/~ellenberg/" rel="external nofollow noopener" target="_blank">Prof. Jordan Ellenberg</a>. This marked the first time an LLM made a new discovery for such a challenging scientific problem, outperforming state-of-the-art computational solvers.</p> <p><img src="/assets/img/capset.png" alt="Benefits of FunSearch" class="l-body rounded z-depth-1 center" width="30%"></p> <div class="l-gutter caption"> <p><strong>Figure 2.</strong> Illustration of the cap set problem. The circles are the elements of $\mathbb{Z}_3^2$ with the ones belonging to the cap set shown in blue. The possible lines in $\mathbb{Z}_3^2$ are also shown (with colours indicating lines that wrap around in arithmetic modulo 3). No three elements of the cap set are in a line.</p> </div> <p>A significant advantage of FunSearch is that it does not just provide solutions. It generates programs that describe <em>how</em> these solutions are constructed. FunSearch also favors highly compact, concise programs, making them easier for researchers to comprehend and learn from.</p> <blockquote> <p>“The solutions generated by FunSearch are <strong>far conceptually richer</strong> than a mere list of numbers. When I study them, I learn something.” — Jordan Ellenberg, Professor of Mathematics at the University of Wisconsin–Madison</p> </blockquote> <p><img src="/assets/img/funsearch_code.png" alt="Code generated by FunSearch" class="l-body rounded z-depth-1 center" width="80%"></p> <div class="l-gutter caption"> <p><strong>Figure 3.</strong> Code generated by FunSearch for the cap set problem.</p> </div> <p>The success of FunSearch <d-cite key="romera2024mathematical"></d-cite> underscores that LLMs, when carefully guided and their outputs rigorously verified, can be powerful engines for scientific discovery.</p> <h2 id="alphaevolve">AlphaEvolve</h2> <p>More recently, in May 2025, Google DeepMind announced <a href="https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/" rel="external nofollow noopener" target="_blank">AlphaEvolve</a>, an evolutionary coding agent powered by large language models for general-purpose algorithm discovery and optimization<d-cite key="deepmind2025alphaevolve"></d-cite>. This development builds upon the success of systems like FunSearch and represents a significant step towards leveraging AI for complex problem-solving across various domains. Unlike FunSearch, which focuses on discovering single functions, AlphaEvolve is designed to evolve entire codebases and develop much more intricate algorithms.</p> <h3 id="how-alphaevolve-works">How AlphaEvolve works</h3> <p><img src="/assets/img/alphaevolve.png" alt="Overview of AlphaEvolve" class="l-body rounded z-depth-1 center" width="80%"></p> <div class="l-gutter caption"> <p><strong>Figure 4.</strong> The AlphaEvolve process. A prompt sampler assembles prompts for the LLMs, which generate new programs. These are then evaluated and stored in a programs database, which uses an evolutionary algorithm to select programs for future prompts.</p> </div> <p>AlphaEvolve uses an evolutionary approach with four key components (see Figure 4):</p> <ol> <li> <p><strong>Prompt sampler:</strong> The prompt contains rich context based on previously discovered solutions, along with instructions for proposing changes to particular solutions.</p> </li> <li> <p><strong>LLM ensemble:</strong> Unlike FunSearch that uses a single LLM, AlphaEvolve uses an ensemble approach combining <a href="https://deepmind.google/discover/blog/gemini-flash-a-new-generation-of-large-language-models-with-fast-inference-and-high-quality-outputs/" rel="external nofollow noopener" target="_blank">Gemini Flash</a> and <a href="https://deepmind.google/discover/blog/gemini-pro-a-new-generation-of-large-language-models-with-high-quality-outputs/" rel="external nofollow noopener" target="_blank">Gemini Pro</a>. The lightweight Gemini Flash enables higher rates of candidate generation through lower latency, while the more powerful Gemini Pro provides deeper insights and higher-quality suggestions that can significantly advance the evolutionary search and potentially lead to breakthroughs.</p> </li> <li> <p><strong>Evaluator pool:</strong> This component verifies, runs, and scores proposed solutions using automated evaluation metrics that provide objective assessments of each solution’s accuracy and quality.</p> </li> <li> <p><strong>Program database:</strong> AlphaEvolve uses an evolutionary database inspired by a combination of the MAP elites algorithm<d-cite key="mouret2015illuminating"></d-cite> and island-based population models<d-cite key="tanese1989distributed"></d-cite> to continuously improve upon the best solutions while maintaining diversity to encourage exploration.</p> </li> </ol> <p>Unlike traditional genetic algorithms with explicit mutation and crossover operations, AlphaEvolve uses LLMs as sophisticated genetic operators to generate code modifications based on context from past solutions. Mutation occurs when the LLM ensemble suggests code changes (e.g., rewrites or targeted diffs), while crossover is implicit as the LLM receives multiple parent solutions as inspiration. This approach makes AlphaEvolve particularly effective in domains where progress can be clearly and systematically measured, like mathematics and computer science.</p> <h3 id="benefits-of-alphaevolve">Benefits of AlphaEvolve</h3> <p>AlphaEvolve has already demonstrated significant real-world impact across multiple domains:</p> <ol> <li> <p><strong>Improving data center scheduling:</strong> AlphaEvolve discovered a simple yet highly effective heuristic to help <a href="https://research.google/pubs/large-scale-cluster-management-at-google-with-borg/" rel="external nofollow noopener" target="_blank">Borg</a>, Google’s cluster management system, orchestrate its vast data centers more efficiently. This solution, which has been in production for over a year, continuously recovers, on average, 0.7% of Google’s worldwide compute resources. This sustained efficiency gain allows more tasks to be completed on the same computational footprint. A key benefit is that AlphaEvolve’s solution is human-readable code, offering interpretability, debuggability, predictability, and ease of deployment.</p> </li> <li> <p><strong>Hardware design optimization:</strong> AlphaEvolve proposed a <a href="https://en.wikipedia.org/wiki/Verilog" rel="external nofollow noopener" target="_blank">Verilog</a> rewrite that removed unnecessary bits in a key, highly optimized arithmetic circuit for matrix multiplication. The proposal passed robust verification methods to confirm functional correctness and was integrated into an upcoming Tensor Processing Unit (TPU). By suggesting modifications in the standard language of chip designers, AlphaEvolve promotes collaboration between AI and hardware engineers to accelerate specialized chip design.</p> </li> <li> <p><strong>Enhancing AI training and inference:</strong> AlphaEvolve found more efficient ways to divide large matrix multiplication operations into manageable subproblems, achieving a 23% speedup in Gemini’s architecture’s vital <a href="https://docs.jax.dev/en/latest/pallas/index.html" rel="external nofollow noopener" target="_blank">kernel</a>, resulting in a 1% reduction in overall training time. In the realm of low-level GPU optimization, AlphaEvolve demonstrated remarkable efficiency by achieving up to a 32.5% speedup for the <a href="https://arxiv.org/abs/2205.14135" rel="external nofollow noopener" target="_blank">FlashAttention</a> kernel implementation in Transformer-based AI models.</p> </li> </ol> <p><img src="/assets/img/alphaevolve_applications.png" alt="Overview of AlphaEvolve" class="l-body rounded z-depth-1 center" width="80%"></p> <div class="l-gutter caption"> <p><strong>Figure 6.</strong> How AlphaEvolve helps Google deliver a more efficient digital ecosystem, from data center scheduling and hardware design to AI model training.</p> </div> <p>Beyond these applications, AlphaEvolve made a groundbreaking contribution by discovering an algorithm for multiplying 4x4 complex-valued matrices using just 48 scalar multiplications, surpassing the efficiency of <a href="https://en.wikipedia.org/wiki/Strassen_algorithm" rel="external nofollow noopener" target="_blank">Strassen’s 1969 algorithm</a>. When applied to a diverse set of over 50 open problems spanning mathematical analysis, geometry, combinatorics, and number theory, AlphaEvolve demonstrated remarkable versatility: it successfully rediscovered state-of-the-art solutions in 75% of cases and improved upon previously best-known solutions in 20% of cases. One of its most notable achievements was advancing the <a href="https://plus.maths.org/content/newton-and-kissing-problem" rel="external nofollow noopener" target="_blank">300-year-old kissing number problem</a>, where it discovered a configuration of 593 outer spheres and established a new lower bound in 11 dimensions, showcasing its ability to tackle complex geometric challenges.</p> <p><img src="/assets/img/alphaevolve_math.png" alt="Overview of AlphaEvolve" class="l-body rounded z-depth-1 center" width="80%"></p> <div class="l-gutter caption"> <p><strong>Figure 7.</strong> Examples of ground-breaking mathematical contributions discovered with AlphaEvolve.</p> </div> <aside class="l-body box-note"> <p>Looking ahead, AlphaEvolve is expected to continue improving alongside the capabilities of large language models, especially as they become more proficient at coding. Google DeepMind is also planning an <a href="https://docs.google.com/forms/d/e/1FAIpQLSfaLUgKtUOJWdQtyLNAYb3KAkABAlKDmZoIqPbHtwmy3YXlCg/viewform" rel="external nofollow noopener" target="_blank">Early Access Program</a> for selected academic users and exploring possibilities to make AlphaEvolve more broadly available. While currently focused on math and computing, its general nature means it could potentially transform many other areas such as material science, drug discovery, sustainability, and broader applications.</p> </aside> <h2 id="funsearch-vs-alphaevolve">FunSearch vs AlphaEvolve</h2> <p>While both FunSearch and AlphaEvolve leverage LLM within an evolutionary framework, AlphaEvolve offers a substantial improvement over its predecessor, both in terms of scale and generality. Here’s a detailed comparison of their capabilities:</p> <table> <thead> <tr> <th>Capability</th> <th>FunSearch</th> <th>AlphaEvolve</th> </tr> </thead> <tbody> <tr> <td>Code Scope</td> <td>Evolves a single function</td> <td>Evolves an entire codebase</td> </tr> <tr> <td>Code Size</td> <td>Evolves up to 10-20 lines of code</td> <td>Evolves up to hundreds of lines of code</td> </tr> <tr> <td>Language Support</td> <td>Python only</td> <td>Any programming language</td> </tr> <tr> <td>Computation</td> <td>Needs fast evaluation (≤ 20min on 1 CPU)</td> <td>Can evaluate for hours, in parallel, on accelerators</td> </tr> <tr> <td>LLM Usage</td> <td>Millions of LLM samples used</td> <td>Thousands of LLM samples suffice</td> </tr> <tr> <td>Model Scale</td> <td>Small LLMs used, no benefit from using larger models</td> <td>Benefits from using state-of-the-art LLMs</td> </tr> <tr> <td>Context Handling</td> <td>Minimal context (only previous solutions)</td> <td>Rich context and feedback in prompts</td> </tr> <tr> <td>Optimization</td> <td>Optimizes a single metric</td> <td>Can simultaneously optimize multiple metrics</td> </tr> </tbody> </table> <aside class="l-body box-im"> <p>The evolution from FunSearch to AlphaEvolve demonstrates significant advances in <strong>scale</strong> and <strong>generality</strong>. While FunSearch was groundbreaking in showing how LLMs could aid mathematical discovery, AlphaEvolve extends this approach to tackle more complex, real-world problems across multiple domains. This progression also reflects the rapid advancement in LLM capabilities, where newer state-of-the-art models can generate more sophisticated and accurate code with fewer samples.</p> </aside> <h2 id="takeaways">Takeaways</h2> <p>The development of FunSearch<d-cite key="romera2024mathematical"></d-cite> and AlphaEvolve<d-cite key="deepmind2025alphaevolve"></d-cite> marks an exciting advancement in the application of LLMs. Overall, these systems demonstrate LLMs are moving beyond text generation and coding assistance to become tools for genuine discovery and sophisticated optimization in mathematics, computer science, and engineering. Combining LLM creativity with rigorous, automated evaluation within an evolutionary framework is a powerful and promising strategy for tackling complex, real-world problems by evolving entire codebases. While the journey is still ongoing, the prospect of LLMs significantly augmenting, or even leading in some cases, algorithmic and mathematical discovery is becoming increasingly tangible.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/2025-05-15-llm-algorithm-discovery.bib"></d-bibliography> <div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"richardcsuwandi/richardcsuwandi.github.io","data-repo-id":"R_kgDOL_rwfw","data-category":"General","data-category-id":"DIC_kwDOL_rwf84CigRl","data-mapping":"title","data-strict":"0","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 Richard Cornelius Suwandi. Last updated: June 08, 2025. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>