<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://richardcsuwandi.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://richardcsuwandi.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-05-12T04:12:17+00:00</updated><id>https://richardcsuwandi.github.io/feed.xml</id><title type="html">Richard Cornelius Suwandi</title><subtitle></subtitle><entry><title type="html">Learning with a Goal</title><link href="https://richardcsuwandi.github.io/blog/2024/learn-with-a-goal/" rel="alternate" type="text/html" title="Learning with a Goal"/><published>2024-09-15T17:00:00+00:00</published><updated>2024-09-15T17:00:00+00:00</updated><id>https://richardcsuwandi.github.io/blog/2024/learn-with-a-goal</id><content type="html" xml:base="https://richardcsuwandi.github.io/blog/2024/learn-with-a-goal/"><![CDATA[<p>Traditionally, Bayesian optimization (BO) has been perceived as a technique for optimizing expensive objective functions through efficient data sampling, while active learning (AL) is often seen as a way to selectively query data to improve model performance. Recently, Fiore et al. (2024)<d-cite key="di2024active"></d-cite> proposed a unified perspective of BO and AL, arguing that both can be viewed as adaptive sampling schemes guided by common learning principles toward a given optimization goal. In this post, we will explore the key ideas presented in the paper and discuss the implications of this unified perspective.</p> <h2 id="goal-driven-learning">Goal-driven learning</h2> <p>Goal-driven learning<d-cite key="bui2007goal"></d-cite> can described as:</p> <aside class="l-body box-note"> <p>a decision-making process in which each decision is made to acquire specific information about the system of interest that contributes the most to achieve a given a goal.</p> </aside> <p>BO and AL can be regarded as goal-driven procedures, where a surrogate model is built to capture the behavior of a system or effectively inform an optimization procedure to minimize the given objective. This goal-driven process seeks to determine the ‚Äúbest‚Äù location of the domain to acquire information about the system, and refine the surrogate model towards the goal. Mathematically, it can be formulated as:</p> <p>\[ x^* = \arg \min_{x \in \mathcal{X}} f(R(x)) \]</p> <p>where \(f\) is the objective and \(R(x)\) is the response of the system. Here, \(f\) may represent the error between the surrogate approximation and the response, such that the goal is to minimize the error to improve the accuracy of the surrogate. Alternatively, \(f\) may also represents a performance indicator based on the response, so the goal is to minimize this indicator to improve the system‚Äôs performance.</p> <h2 id="adaptive-sampling">Adaptive sampling</h2> <p>BO and AL use adaptive sampling schemes to efficiently accomplish a given goal while adapting to the previously collected information:</p> <ul> <li>In BO, the goal is to minimize the objective function by iteratively selecting the next location to sample based on the surrogate model. The surrogate model is updated after each sample to refine the approximation and guide the next decision.</li> <li>In AL, the goal is to minimize the generalization error of a model by iteratively selecting the next sample to improve the model‚Äôs performance. The model is updated after each sample to refine the approximation and guide the next decision.</li> </ul> <p>We can further classify adaptive sampling schemes into three main categories:</p> <table> <thead> <tr> <th>Category</th> <th>Description</th> </tr> </thead> <tbody> <tr> <td>Adaptive Probing</td> <td>Methods that do not rely on a surrogate model and directly probe the system to gather information in a sequential manner.</td> </tr> <tr> <td>Adaptive Modeling</td> <td>Methods that compute a surrogate model independently, without using it to inform the sampling process.</td> </tr> <tr> <td>Adaptive Learning</td> <td>Methods that use information from the surrogate model to make decisions and update the model based on those decisions.</td> </tr> </tbody> </table> <p>The key distinction between these categories lies in the concept of <em>goal-driven learning</em>, which is the distinctive element of the adaptive learning class. In this paradigm, the learner actively gathers information from the surrogate model to guide its decisions towards the desired goal, and the surrogate model is consequently improved by the outcome of these decisions.</p> <p>In contrast, the adaptive probing and adaptive modeling classes do not exhibit this goal-driven learning characteristic. Adaptive probing methods operate without the aid of a surrogate, while adaptive modeling approaches compute a surrogate that is not directly used to inform the sampling process.</p> <p><img src="/assets/img/adaptive_sampling.png" alt="transformer" class="l-body rounded z-depth-1 center" width="80%"/></p> <div class="l-gutter caption"> <p><strong>Figure 1.</strong> Classification of adaptive sampling techniques: Where adaptive sampling and active learning meet.</p> </div> <h2 id="learning-and-infill-criteria">Learning and infill criteria</h2> <p>The strong synergy between AL and BO is rooted in the substantial analogy between the learning criteria that drive the AL procedure and the infill criteria that characterize the BO scheme.</p> <h3 id="learning-criteria">Learning criteria</h3> <p>Learning criteria establish a metric for quantifying the gains of all the possible learner decisions, and prescribe an optimal decision based in information acquired from the surrogate model. In AL, there are 3 essential learning criteria<d-cite key="he2014active"></d-cite>:</p> <ol> <li><strong>Informativeness:</strong> The sampling policy is driven by the goal of acquiring the <em>most informative samples</em>, i.e., the ones that are expected to contribute the maximum information.</li> <li><strong>Representativeness:</strong> The sampling policy aims to select <em>samples that are representative</em> of the target domain, exploiting the structure of the problem to direct queries to locations</li> <li><strong>Diversity:</strong> The sampling policy seeks to select <em>samples that are diverse</em>, i.e., well-spread across the domain, preventing the concentration of queries in small local regions.</li> </ol> <p><img src="/assets/img/learning_criteria.png" alt="transformer" class="l-body rounded z-depth-1 center" width="100%"/></p> <div class="l-gutter caption"> <p><strong>Figure 2.</strong> Illustration of the three learning criteria in watering optimization problem: (a) informativeness, (b) representativeness, and (c) diversity.</p> </div> <h3 id="infill-criteria">Infill criteria</h3> <p>On the other hand, the infill criteria in BO provides a measure of the information gain that would result from sampling at a particular location. The most common infill criteria are<d-cite key="garnett2023bayesian"></d-cite>:</p> <ol> <li><strong>Global exploration:</strong> This criterion focuses on choosing samples in regions of <em>high predictive uncertainty</em>, enhancing global awareness of the search space. However, this approach may not direct resources optimally towards the specific goal.</li> <li><strong>Local exploitation:</strong> This criterion prioritizes choosing samples in regions with <em>high predictive mean</em>, focusing the search on promising areas. Yet, it may result in less accurate knowledge of the overall objective function distribution.</li> </ol> <aside class="l-body box-important"> <p>Overall, we can observe a strong correspondence between the learning criteria in AL and the infill criteria in BO:</p> <ul> <li><strong>The ‚Äúinformativeness‚Äù criterion in AL aligns with the ‚Äúlocal exploitation‚Äù criterion in BO</strong>, as both aim to maximize the information gain.</li> <li>Similarly, <strong>the ‚Äúrepresentativeness‚Äù and ‚Äúdiversity‚Äù criteria in AL correspond to the ‚Äúglobal exploration‚Äù criterion in BO</strong>, as they seek to ensure that the sampling process is well-distributed across the domain.</li> </ul> </aside> <h2 id="takeaways">Takeaways</h2> <p>BO and AL have traditionally been viewed as distinct fields with separate goals and methodologies. However, this paper provides a unified perspective that highlights the shared principles underlying both fields. By recognizing the synergy between BO and AL, we can leverage the strengths of each field to develop more powerful and efficient learning algorithms.</p>]]></content><author><name>Richard Cornelius Suwandi</name></author><category term="paper-summary"/><category term="bayesian-optimization"/><category term="active-learning"/><summary type="html"><![CDATA[A unified perspective of Bayesian optimization and active learning]]></summary></entry><entry><title type="html">Gaussian Process in Action</title><link href="https://richardcsuwandi.github.io/blog/2021/gp-in-action/" rel="alternate" type="text/html" title="Gaussian Process in Action"/><published>2021-09-20T17:00:00+00:00</published><updated>2021-09-20T17:00:00+00:00</updated><id>https://richardcsuwandi.github.io/blog/2021/gp-in-action</id><content type="html" xml:base="https://richardcsuwandi.github.io/blog/2021/gp-in-action/"><![CDATA[<p>Gaussian processes (GPs) are a powerful yet often underappreciated model in machine learning. As a non-parametric and Bayesian approach, GPs are particularly effective for supervised learning tasks such as regression and classification. Compared to other models, GPs offer several practical advantages:</p> <ul> <li>They perform well even with small datasets.</li> <li>They provide uncertainty quantification for predictions.</li> </ul> <p>In this tutorial, we will implement GP regression using GPyTorch, a GP library built on <a href="https://pytorch.org">PyTorch</a> that is designed for creating scalable and flexible GP models. To learn more about GPyTorch, I recommend visiting their <a href="https://gpytorch.ai/">official website</a>.</p> <aside class="l-body box-warning"> <p><strong>Note:</strong> If you want to follow along with this tutorial, you can find the notebook <a href="https://github.com/richardcsuwandi/gp/blob/main/GP%20Regression%20using%20GPyTorch.ipynb">here</a>.</p> </aside> <h2 id="setup">Setup</h2> <p>Before we begin, we need to install the <code class="language-plaintext highlighter-rouge">gpytorch</code> library. You can do this using either <code class="language-plaintext highlighter-rouge">pip</code> or <code class="language-plaintext highlighter-rouge">conda</code> with the following commands:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>gpytorch <span class="c"># using pip</span>
conda <span class="nb">install </span>gpytorch <span class="nt">-c</span> gpytorch <span class="c"># using conda</span>
</code></pre></div></div> <h2 id="generating-the-data">Generating the data</h2> <p>Next, we will generate training data for our model by modeling the following function:</p> \[y = \sin{(2\pi x)} + \epsilon, \epsilon \sim \mathcal{N}(0,0.04)\] <p>We will evaluate this function at 15 equally spaced points in the interval \([0,1]\). The generated training data is illustrated in the following plot:</p> <p><img src="/assets/img/gpr_data.png" alt="transformer" class="l-body rounded z-depth-1 center" width="70%"/></p> <div class="l-gutter caption"> <p><strong>Figure 1.</strong> The generated training data by evaluating the true function on 15 equally-spaced points from \([0,1]\).</p> </div> <h2 id="building-the-model">Building the model</h2> <p>Now that we have our training data, we can start building our GP model. GPyTorch provides a flexible framework for constructing GP models, similar to building neural networks in standard PyTorch. For most GP regression models, you will need to create the following components:</p> <aside class="l-body box-note"> <ul> <li><strong>A GP model:</strong> For exact (non-variational) GP models, use <code class="language-plaintext highlighter-rouge">gpytorch.models.ExactGP</code>.</li> <li><strong>A likelihood function:</strong> For GP regression, we typically use <code class="language-plaintext highlighter-rouge">gpytorch.likelihoods.GaussianLikelihood</code>.</li> <li><strong>A mean function:</strong> This serves as the prior mean of the GP. If you‚Äôre unsure which mean function to use, <code class="language-plaintext highlighter-rouge">gpytorch.means.ConstantMean</code> is a good starting point.</li> <li><strong>A kernel function:</strong> This defines the prior covariance of the GP. For this tutorial, we will use the <a href="https://arxiv.org/pdf/1302.4245.pdf">spectral mixture (SM)</a> kernel (<code class="language-plaintext highlighter-rouge">gpytorch.kernels.SpectralMixtureKernel</code>).</li> <li><strong>A multivariate normal distribution:</strong> Represented by <code class="language-plaintext highlighter-rouge">gpytorch.distributions.MultivariateNormal</code>.</li> </ul> </aside> <p>We can build our GP model by assembling these components as follows:</p> <details><summary>Show code</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">SpectralMixtureGP</span><span class="p">(</span><span class="n">gpytorch</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="n">ExactGP</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">SpectralMixtureGP</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">gpytorch</span><span class="p">.</span><span class="n">means</span><span class="p">.</span><span class="nc">ConstantMean</span><span class="p">()</span> <span class="c1"># Construct the mean function
</span>        <span class="n">self</span><span class="p">.</span><span class="n">cov</span> <span class="o">=</span> <span class="n">gpytorch</span><span class="p">.</span><span class="n">kernels</span><span class="p">.</span><span class="nc">SpectralMixtureKernel</span><span class="p">(</span><span class="n">num_mixtures</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span> <span class="c1"># Construct the kernel function
</span>        <span class="n">self</span><span class="p">.</span><span class="n">cov</span><span class="p">.</span><span class="nf">initialize_from_data</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="c1"># Initialize the hyperparameters from data
</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Evaluate the mean and kernel function at x
</span>        <span class="n">mean_x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">cov_x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">cov</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># Return the multivariate normal distribution using the evaluated mean and kernel function
</span>        <span class="k">return</span> <span class="n">gpytorch</span><span class="p">.</span><span class="n">distributions</span><span class="p">.</span><span class="nc">MultivariateNormal</span><span class="p">(</span><span class="n">mean_x</span><span class="p">,</span> <span class="n">cov_x</span><span class="p">)</span> 

<span class="c1"># Initialize the likelihood and model
</span><span class="n">likelihood</span> <span class="o">=</span> <span class="n">gpytorch</span><span class="p">.</span><span class="n">likelihoods</span><span class="p">.</span><span class="nc">GaussianLikelihood</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="nc">SpectralMixtureGP</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">)</span>
</code></pre></div></div> </details> <p>Here‚Äôs a breakdown of the code:</p> <aside class="l-body box-important"> <ul> <li>The GP model consists of two main components: the <code class="language-plaintext highlighter-rouge">__init__</code> and <code class="language-plaintext highlighter-rouge">forward</code> methods.</li> <li>The <code class="language-plaintext highlighter-rouge">__init__</code> method initializes the model with training data and a likelihood, constructing necessary objects like the mean and kernel functions.</li> <li>The forward method takes the input data <code class="language-plaintext highlighter-rouge">x</code> and returns a multivariate normal distribution based on the evaluated mean and covariance.</li> <li>We initialize the likelihood function for the GP model using the Gaussian likelihood, which assumes a homoskedastic noise model (i.e., uniform noise across inputs).</li> </ul> </aside> <h2 id="training-the-model">Training the model</h2> <p>With the model built, we can now train it to find the optimal hyperparameters. Training a GP model in GPyTorch is akin to training a neural network in standard PyTorch. The training loop involves the following steps:</p> <ul> <li>Setting all parameter gradients to zero.</li> <li>Calling the model to compute the loss.</li> <li>Backpropagating the loss to compute gradients.</li> <li>Taking a step with the optimizer.</li> </ul> <aside class="l-body box-warning"> <p><strong>Remark:</strong> By creating a custom training loop, we gain greater flexibility in training, such as saving parameters at each step or using different learning rates for different parameters.</p> </aside> <p>Here‚Äôs the code for the training loop:</p> <details><summary>Show code</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Put the model into training mode
</span><span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
<span class="n">likelihood</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>

<span class="c1"># Use the Adam optimizer, with learning rate set to 0.1
</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="c1"># Use the negative marginal log-likelihood as the loss function
</span><span class="n">mll</span> <span class="o">=</span> <span class="n">gpytorch</span><span class="p">.</span><span class="n">mlls</span><span class="p">.</span><span class="nc">ExactMarginalLogLikelihood</span><span class="p">(</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>

<span class="c1"># Set the number of training iterations
</span><span class="n">n_iter</span> <span class="o">=</span> <span class="mi">50</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_iter</span><span class="p">):</span>
    <span class="c1"># Set the gradients from previous iteration to zero
</span>    <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
    <span class="c1"># Output from model
</span>    <span class="n">output</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
    <span class="c1"># Compute loss and backprop gradients
</span>    <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="nf">mll</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Iter %d/%d - Loss: %.3f</span><span class="sh">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_iter</span><span class="p">,</span> <span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()))</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
</code></pre></div></div> </details> <p>In this code, we first set our model to training mode. Then, we define the loss function and optimizer to use during training. We use the negative marginal log-likelihood as the loss and Adam as the optimizer, running the loop for 50 iterations.</p> <h2 id="making-predictions">Making predictions</h2> <p>Finally, we can make predictions with the trained model. The routine for evaluating the model and generating predictions is as follows:</p> <details><summary>Show code</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># The test data is 50 equally-spaced points from [0,5]
</span><span class="n">x_test</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>

<span class="c1"># Put the model into evaluation mode
</span><span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
<span class="n">likelihood</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>

<span class="c1"># The gpytorch.settings.fast_pred_var flag activates LOVE (for fast variances)
# See https://arxiv.org/abs/1803.06058
</span><span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">(),</span> <span class="n">gpytorch</span><span class="p">.</span><span class="n">settings</span><span class="p">.</span><span class="nf">fast_pred_var</span><span class="p">():</span>
    <span class="c1"># Obtain the predictive mean and covariance matrix
</span>    <span class="n">f_preds</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
    <span class="n">f_mean</span> <span class="o">=</span> <span class="n">f_preds</span><span class="p">.</span><span class="n">mean</span>
    <span class="n">f_cov</span> <span class="o">=</span> <span class="n">f_preds</span><span class="p">.</span><span class="n">covariance_matrix</span>

    <span class="c1"># Make predictions by feeding model through likelihood
</span>    <span class="n">observed_pred</span> <span class="o">=</span> <span class="nf">likelihood</span><span class="p">(</span><span class="nf">model</span><span class="p">(</span><span class="n">x_test</span><span class="p">))</span>

    <span class="c1"># Initialize plot
</span>    <span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="c1"># Get upper and lower confidence bounds
</span>    <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span> <span class="o">=</span> <span class="n">observed_pred</span><span class="p">.</span><span class="nf">confidence_region</span><span class="p">()</span>
    <span class="c1"># Plot training data as black stars
</span>    <span class="n">ax</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x_train</span><span class="p">.</span><span class="nf">numpy</span><span class="p">(),</span> <span class="n">y_train</span><span class="p">.</span><span class="nf">numpy</span><span class="p">(),</span> <span class="sh">'</span><span class="s">k*</span><span class="sh">'</span><span class="p">)</span>
    <span class="c1"># Plot predictive means as blue line
</span>    <span class="n">ax</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x_test</span><span class="p">.</span><span class="nf">numpy</span><span class="p">(),</span> <span class="n">observed_pred</span><span class="p">.</span><span class="n">mean</span><span class="p">.</span><span class="nf">numpy</span><span class="p">(),</span> <span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">)</span>
    <span class="c1"># Shade between the lower and upper confidence bounds
</span>    <span class="n">ax</span><span class="p">.</span><span class="nf">fill_between</span><span class="p">(</span><span class="n">x_test</span><span class="p">.</span><span class="nf">numpy</span><span class="p">(),</span> <span class="n">lower</span><span class="p">.</span><span class="nf">numpy</span><span class="p">(),</span> <span class="n">upper</span><span class="p">.</span><span class="nf">numpy</span><span class="p">(),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">set_ylim</span><span class="p">([</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">legend</span><span class="p">([</span><span class="sh">'</span><span class="s">Observed Data</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Mean</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Confidence</span><span class="sh">'</span><span class="p">])</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> </details> <p>The above code performs several things:</p> <aside class="l-body box-important"> <ul> <li>It generates test data using 50 equally spaced points from \([0, 5]\).</li> <li>The model is set to evaluation mode, and we utilize <code class="language-plaintext highlighter-rouge">gpytorch.settings.fast_pred_var()</code> for faster predictive distributions.</li> <li>The trained GP model returns a MultivariateNormal distribution containing the posterior mean and covariance, from which we extract the predictive mean and covariance matrix.</li> <li>Finally, we plot the mean and confidence region of the fitted GP model. The <code class="language-plaintext highlighter-rouge">confidence_region()</code> method provides the upper and lower bounds, representing two standard deviations above and below the mean.</li> </ul> </aside> <p>The resulting plot is shown below:</p> <p><img src="/assets/img/gpr_pred.png" alt="transformer" class="l-body rounded z-depth-1 center" width="70%"/></p> <div class="l-gutter caption"> <p><strong>Figure 2.</strong> Plot of the fitted GP model given by the mean (blue line) and confidence region (shaded area). The observed data (black stars) is also plotted in the figure.</p> </div> <p>In this plot, the black stars (‚òÖ) represent the training (observed) data, while the blue line and shaded area (üü¶) indicate the mean and confidence bounds, respectively. Notice how the uncertainty decreases near the observed points. If we added more data points, we would see the mean function adjust to pass through them, further reducing uncertainty close to the observations.</p> <h2 id="takeaways">Takeaways</h2> <p>In this tutorial, we learned how to build a GP model using GPyTorch. There are many additional <a href="https://docs.gpytorch.ai/en/latest/">features</a> in GPyTorch that I did not cover here. I hope this tutorial serves as a solid foundation for you to explore GPyTorch and Gaussian processes further.</p>]]></content><author><name>Richard Cornelius Suwandi</name></author><category term="tutorial"/><category term="gaussian-process"/><category term="machine-learning"/><summary type="html"><![CDATA[Building a Gaussian process model with GPyTorch]]></summary></entry></feed>