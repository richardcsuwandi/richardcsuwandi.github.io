<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://richardcsuwandi.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://richardcsuwandi.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-05-23T19:05:11+00:00</updated><id>https://richardcsuwandi.github.io/feed.xml</id><title type="html">Richard Cornelius Suwandi</title><subtitle></subtitle><entry><title type="html">Can we use LLMs to discover new algorithms?</title><link href="https://richardcsuwandi.github.io/blog/2025/llm-algorithm-discovery/" rel="alternate" type="text/html" title="Can we use LLMs to discover new algorithms?"/><published>2025-05-15T03:00:00+00:00</published><updated>2025-05-15T03:00:00+00:00</updated><id>https://richardcsuwandi.github.io/blog/2025/llm-algorithm-discovery</id><content type="html" xml:base="https://richardcsuwandi.github.io/blog/2025/llm-algorithm-discovery/"><![CDATA[<p>Large language models (LLMs) have rapidly become indispensable AI assistants. They excel at synthesizing concepts, writing, and coding to help humans solve complex problems<d-cite key="chen2021evaluating"></d-cite> . But could they discover entirely new knowledge? As LLMs have been shown to “hallucinate”<d-cite key="farquhar2024detecting"></d-cite> factually incorrect information, using them to make verifiably correct discoveries is a challenge. But what if we could harness the creativity of LLMs by identifying and building upon only their very best ideas? This question is at the heart of recent breakthroughs from <a href="https://deepmind.google/">Google DeepMind</a>, which explore how LLMs can be guided to make novel discoveries in mathematics and algorithm design. This post delves into two pioneering works, FunSearch and the more recent AlphaEvolve, showcasing their approaches and implications for the future of automated algorithm discovery.</p> <h2 id="funsearch">FunSearch</h2> <p>In a paper published in Nature<d-cite key="romera2024mathematical"></d-cite>, Google DeepMind introduced <a href="https://deepmind.google/discover/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/">FunSearch</a>, a groundbreaking method demonstrating that LLMs can make new discoveries in mathematical sciences. The core idea is to search for novel “functions” written in computer code, hence the name FunSearch. FunSearch tackles the trade-off between LLMs’ creativity and correctness by pairing a pre-trained LLM with an automated “evaluator.” This evaluator guards against hallucinations and incorrect ideas, ensuring that the system builds upon solid foundations.</p> <h3 id="how-funsearch-works">How FunSearch works</h3> <p><img src="/assets/img/funsearch.png" alt="Overview of FunSearch" class="l-body rounded z-depth-1 center" width="80%"/></p> <div class="l-gutter caption"> <p><strong>Figure 1.</strong> The FunSearch process. The LLM is shown a selection of the best programs it has generated so far, and asked to generate an even better one. The programs proposed by the LLM are automatically executed, and evaluated. The best programs are added to the database, for selection in subsequent cycles.</p> </div> <p>FunSearch uses an evolutionary approach<d-cite key="mouret2015illuminating"></d-cite><d-cite key="tanese1989distributed"></d-cite>. To start, the user writes a description of the problem in code. This includes a way to evaluate programs and an initial “seed” program to begin the process. The system then follows these steps:</p> <ol> <li>It selects the most promising programs from the current database.</li> <li>These programs are sent to an LLM<d-footnote>In their work, Google's PaLM 2 was used, though other code-trained LLMs can also work.</d-footnote>, which creatively builds upon them to generate new program proposals.</li> <li>The new programs are automatically run and checked by the evaluator.</li> <li>The best-performing valid programs are added back into the database, improving the database for the next round.</li> </ol> <aside class="l-body box-note"> <p>This cycle of selection, generation, evaluation, and update creates a <em>self-improving loop</em>. Starting from basic knowledge about the problem and using strategies to keep the database diverse, FunSearch is able to evolve simple solutions into more advanced ones. It can solve complex problems where human intuition might fall short.</p> </aside> <h3 id="benefits-of-funsearch">Benefits of FunSearch</h3> <p>FunSearch’s capabilities were tested on challenging problems. For example, it was used to solve the <strong><a href="https://en.wikipedia.org/wiki/Cap_set">cap set problem</a></strong>, which involves finding the largest set of points in a high-dimensional grid where no three points lie on a line. This longstanding open problem in extremal combinatorics, once described by renowned mathematician Terence Tao as his <a href="https://terrytao.wordpress.com/2007/02/23/open-question-best-bounds-for-cap-sets/">favorite open question</a>, was solved by FunSearch, in collaboration with <a href="https://people.math.wisc.edu/~ellenberg/">Prof. Jordan Ellenberg</a>. This marked the first time an LLM made a new discovery for such a challenging scientific problem, outperforming state-of-the-art computational solvers.</p> <p><img src="/assets/img/capset.png" alt="Benefits of FunSearch" class="l-body rounded z-depth-1 center" width="30%"/></p> <div class="l-gutter caption"> <p><strong>Figure 2.</strong> Illustration of the cap set problem. The circles are the elements of $\mathbb{Z}_3^2$ with the ones belonging to the cap set shown in blue. The possible lines in $\mathbb{Z}_3^2$ are also shown (with colours indicating lines that wrap around in arithmetic modulo 3). No three elements of the cap set are in a line.</p> </div> <p>A significant advantage of FunSearch is that it does not just provide solutions. It generates programs that describe <em>how</em> these solutions are constructed. FunSearch also favors highly compact, concise programs, making them easier for researchers to comprehend and learn from.</p> <blockquote> <p>“The solutions generated by FunSearch are <strong>far conceptually richer</strong> than a mere list of numbers. When I study them, I learn something.” — Jordan Ellenberg, Professor of Mathematics at the University of Wisconsin–Madison</p> </blockquote> <p><img src="/assets/img/funsearch_code.png" alt="Code generated by FunSearch" class="l-body rounded z-depth-1 center" width="80%"/></p> <div class="l-gutter caption"> <p><strong>Figure 3.</strong> Code generated by FunSearch for the cap set problem.</p> </div> <p>The success of FunSearch <d-cite key="romera2024mathematical"></d-cite> underscores that LLMs, when carefully guided and their outputs rigorously verified, can be powerful engines for scientific discovery.</p> <h2 id="alphaevolve">AlphaEvolve</h2> <p>More recently, in May 2025, Google DeepMind announced <a href="https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/">AlphaEvolve</a>, an evolutionary coding agent powered by large language models for general-purpose algorithm discovery and optimization<d-cite key="deepmind2025alphaevolve"></d-cite>. This development builds upon the success of systems like FunSearch and represents a significant step towards leveraging AI for complex problem-solving across various domains. Unlike FunSearch, which focuses on discovering single functions, AlphaEvolve is designed to evolve entire codebases and develop much more intricate algorithms.</p> <h3 id="how-alphaevolve-works">How AlphaEvolve works</h3> <p><img src="/assets/img/alphaevolve.png" alt="Overview of AlphaEvolve" class="l-body rounded z-depth-1 center" width="80%"/></p> <div class="l-gutter caption"> <p><strong>Figure 4.</strong> The AlphaEvolve process. A prompt sampler assembles prompts for the LLMs, which generate new programs. These are then evaluated and stored in a programs database, which uses an evolutionary algorithm to select programs for future prompts.</p> </div> <p>AlphaEvolve pairs the creative problem-solving capabilities of Google’s Gemini models with automated evaluators. It uses an ensemble approach: <a href="https://deepmind.google/discover/blog/gemini-flash-a-new-generation-of-large-language-models-with-fast-inference-and-high-quality-outputs/">Gemini Flash</a>, the fastest and most efficient model, is used to maximize the breadth of ideas explored, while <a href="https://deepmind.google/discover/blog/gemini-pro-a-new-generation-of-large-language-models-with-high-quality-outputs/">Gemini Pro</a>, the most powerful model, provides critical depth with insightful suggestions. Together, these models propose computer programs that implement algorithmic solutions. These proposed programs are then verified, run, and scored using automated evaluation metrics that provide an objective assessment of each solution’s accuracy and quality. This makes AlphaEvolve particularly effective in domains where progress can be clearly and systematically measured, like mathematics and computer science.</p> <h3 id="benefits-of-alphaevolve">Benefits of AlphaEvolve</h3> <p>AlphaEvolve has already demonstrated significant real-world impact across multiple domains:</p> <ol> <li> <p><strong>Improving data center scheduling:</strong> AlphaEvolve discovered a simple yet highly effective heuristic to help <a href="https://research.google/pubs/large-scale-cluster-management-at-google-with-borg/">Borg</a>, Google’s cluster management system, orchestrate its vast data centers more efficiently. This solution, which has been in production for over a year, continuously recovers, on average, 0.7% of Google’s worldwide compute resources. This sustained efficiency gain allows more tasks to be completed on the same computational footprint. A key benefit is that AlphaEvolve’s solution is human-readable code, offering interpretability, debuggability, predictability, and ease of deployment.</p> </li> <li> <p><strong>Hardware design optimization:</strong> AlphaEvolve proposed a <a href="https://en.wikipedia.org/wiki/Verilog">Verilog</a> rewrite that removed unnecessary bits in a key, highly optimized arithmetic circuit for matrix multiplication. The proposal passed robust verification methods to confirm functional correctness and was integrated into an upcoming Tensor Processing Unit (TPU). By suggesting modifications in the standard language of chip designers, AlphaEvolve promotes collaboration between AI and hardware engineers to accelerate specialized chip design.</p> </li> <li> <p><strong>Enhancing AI training and inference:</strong> AlphaEvolve found more efficient ways to divide large matrix multiplication operations into manageable subproblems, achieving a 23% speedup in Gemini’s architecture’s vital <a href="https://docs.jax.dev/en/latest/pallas/index.html">kernel</a>, resulting in a 1% reduction in overall training time. In the realm of low-level GPU optimization, AlphaEvolve demonstrated remarkable efficiency by achieving up to a 32.5% speedup for the <a href="https://arxiv.org/abs/2205.14135">FlashAttention</a> kernel implementation in Transformer-based AI models.</p> </li> </ol> <p><img src="/assets/img/alphaevolve_applications.png" alt="Overview of AlphaEvolve" class="l-body rounded z-depth-1 center" width="80%"/></p> <div class="l-gutter caption"> <p><strong>Figure 6.</strong> How AlphaEvolve helps Google deliver a more efficient digital ecosystem, from data center scheduling and hardware design to AI model training.</p> </div> <p>Beyond these applications, AlphaEvolve made a groundbreaking contribution by discovering an algorithm for multiplying 4x4 complex-valued matrices using just 48 scalar multiplications, surpassing the efficiency of <a href="https://en.wikipedia.org/wiki/Strassen_algorithm">Strassen’s 1969 algorithm</a>. When applied to a diverse set of over 50 open problems spanning mathematical analysis, geometry, combinatorics, and number theory, AlphaEvolve demonstrated remarkable versatility: it successfully rediscovered state-of-the-art solutions in 75% of cases and improved upon previously best-known solutions in 20% of cases. One of its most notable achievements was advancing the <a href="https://plus.maths.org/content/newton-and-kissing-problem">300-year-old kissing number problem</a>, where it discovered a configuration of 593 outer spheres and established a new lower bound in 11 dimensions, showcasing its ability to tackle complex geometric challenges.</p> <p><img src="/assets/img/alphaevolve_math.png" alt="Overview of AlphaEvolve" class="l-body rounded z-depth-1 center" width="80%"/></p> <div class="l-gutter caption"> <p><strong>Figure 7.</strong> Examples of ground-breaking mathematical contributions discovered with AlphaEvolve.</p> </div> <aside class="l-body box-note"> <p>Looking ahead, AlphaEvolve is expected to continue improving alongside the capabilities of large language models, especially as they become more proficient at coding. Google DeepMind is also planning an <a href="https://docs.google.com/forms/d/e/1FAIpQLSfaLUgKtUOJWdQtyLNAYb3KAkABAlKDmZoIqPbHtwmy3YXlCg/viewform">Early Access Program</a> for selected academic users and exploring possibilities to make AlphaEvolve more broadly available. While currently focused on math and computing, its general nature means it could potentially transform many other areas such as material science, drug discovery, sustainability, and broader applications.</p> </aside> <h2 id="funsearch-vs-alphaevolve">FunSearch vs AlphaEvolve</h2> <p>While both FunSearch and AlphaEvolve leverage evolutionary methods combined with LLMs for algorithm discovery, AlphaEvolve represents a substantial enhancement over its predecessor. Here’s a detailed comparison of their capabilities:</p> <table> <thead> <tr> <th>Capability</th> <th>FunSearch</th> <th>AlphaEvolve</th> </tr> </thead> <tbody> <tr> <td>Code Scope</td> <td>Evolves single function</td> <td>Evolves entire code file</td> </tr> <tr> <td>Code Size</td> <td>Evolves up to 10-20 lines of code</td> <td>Evolves up to hundreds of lines of code</td> </tr> <tr> <td>Language Support</td> <td>Python only</td> <td>Any programming language</td> </tr> <tr> <td>Computation</td> <td>Needs fast evaluation (≤ 20min on 1 CPU)</td> <td>Can evaluate for hours, in parallel, on accelerators</td> </tr> <tr> <td>LLM Usage</td> <td>Millions of LLM samples used</td> <td>Thousands of LLM samples suffice</td> </tr> <tr> <td>Model Scale</td> <td>Small LLMs used, no benefit from using larger models</td> <td>Benefits from using state-of-the-art LLMs</td> </tr> <tr> <td>Context Handling</td> <td>Minimal context (only previous solutions)</td> <td>Rich context and feedback in prompts</td> </tr> <tr> <td>Optimization</td> <td>Optimizes single metric</td> <td>Can simultaneously optimize multiple metrics</td> </tr> </tbody> </table> <aside class="l-body box-note"> <p>The evolution from FunSearch to AlphaEvolve demonstrates significant advances in <strong>scale</strong> and <strong>generality</strong>. While FunSearch was groundbreaking in showing how LLMs could aid mathematical discovery, AlphaEvolve extends this approach to tackle more complex, real-world problems across multiple domains. This progression also reflects the rapid advancement in LLM capabilities, where newer state-of-the-art models can generate more sophisticated and accurate code with fewer samples.</p> </aside> <h2 id="takeaways">Takeaways</h2> <p>The development of FunSearch<d-cite key="romera2024mathematical"></d-cite> and AlphaEvolve<d-cite key="deepmind2025alphaevolve"></d-cite> marks an exciting advancement in the application of LLMs. Overall, these systems demonstrate LLMs are moving beyond text generation and coding assistance to become tools for genuine discovery and sophisticated optimization in mathematics, computer science, and engineering. Combining LLM creativity with rigorous, automated evaluation within an evolutionary framework is a powerful and promising strategy for tackling complex, real-world problems by evolving entire codebases. While the journey is still ongoing, the prospect of LLMs significantly augmenting, or even leading in some cases, algorithmic and mathematical discovery is becoming increasingly tangible.</p>]]></content><author><name>Richard Cornelius Suwandi</name></author><category term="paper-summary"/><category term="large-language-models"/><category term="agents"/><summary type="html"><![CDATA[A review of FunSearch and AlphaEvolve]]></summary></entry><entry><title type="html">Learning with a Goal</title><link href="https://richardcsuwandi.github.io/blog/2024/learn-with-a-goal/" rel="alternate" type="text/html" title="Learning with a Goal"/><published>2024-09-15T17:00:00+00:00</published><updated>2024-09-15T17:00:00+00:00</updated><id>https://richardcsuwandi.github.io/blog/2024/learn-with-a-goal</id><content type="html" xml:base="https://richardcsuwandi.github.io/blog/2024/learn-with-a-goal/"><![CDATA[<p>Traditionally, Bayesian optimization (BO) has been perceived as a technique for optimizing expensive objective functions through efficient data sampling, while active learning (AL) is often seen as a way to selectively query data to improve model performance. Recently, Fiore et al. (2024)<d-cite key="di2024active"></d-cite> proposed a unified perspective of BO and AL, arguing that both can be viewed as adaptive sampling schemes guided by common learning principles toward a given optimization goal. In this post, we will explore the key ideas presented in the paper and discuss the implications of this unified perspective.</p> <h2 id="goal-driven-learning">Goal-driven learning</h2> <p>Goal-driven learning<d-cite key="bui2007goal"></d-cite> can described as:</p> <aside class="l-body box-note"> <p>a decision-making process in which each decision is made to acquire specific information about the system of interest that contributes the most to achieve a given a goal.</p> </aside> <p>BO and AL can be regarded as goal-driven procedures, where a surrogate model is built to capture the behavior of a system or effectively inform an optimization procedure to minimize the given objective. This goal-driven process seeks to determine the “best” location of the domain to acquire information about the system, and refine the surrogate model towards the goal. Mathematically, it can be formulated as:</p> <p>\[ x^* = \arg \min_{x \in \mathcal{X}} f(R(x)) \]</p> <p>where \(f\) is the objective and \(R(x)\) is the response of the system. Here, \(f\) may represent the error between the surrogate approximation and the response, such that the goal is to minimize the error to improve the accuracy of the surrogate. Alternatively, \(f\) may also represents a performance indicator based on the response, so the goal is to minimize this indicator to improve the system’s performance.</p> <h2 id="adaptive-sampling">Adaptive sampling</h2> <p>BO and AL use adaptive sampling schemes to efficiently accomplish a given goal while adapting to the previously collected information:</p> <ul> <li>In BO, the goal is to minimize the objective function by iteratively selecting the next location to sample based on the surrogate model. The surrogate model is updated after each sample to refine the approximation and guide the next decision.</li> <li>In AL, the goal is to minimize the generalization error of a model by iteratively selecting the next sample to improve the model’s performance. The model is updated after each sample to refine the approximation and guide the next decision.</li> </ul> <p>We can further classify adaptive sampling schemes into three main categories:</p> <table> <thead> <tr> <th>Category</th> <th>Description</th> </tr> </thead> <tbody> <tr> <td>Adaptive Probing</td> <td>Methods that do not rely on a surrogate model and directly probe the system to gather information in a sequential manner.</td> </tr> <tr> <td>Adaptive Modeling</td> <td>Methods that compute a surrogate model independently, without using it to inform the sampling process.</td> </tr> <tr> <td>Adaptive Learning</td> <td>Methods that use information from the surrogate model to make decisions and update the model based on those decisions.</td> </tr> </tbody> </table> <p>The key distinction between these categories lies in the concept of <em>goal-driven learning</em>, which is the distinctive element of the adaptive learning class. In this paradigm, the learner actively gathers information from the surrogate model to guide its decisions towards the desired goal, and the surrogate model is consequently improved by the outcome of these decisions.</p> <p>In contrast, the adaptive probing and adaptive modeling classes do not exhibit this goal-driven learning characteristic. Adaptive probing methods operate without the aid of a surrogate, while adaptive modeling approaches compute a surrogate that is not directly used to inform the sampling process.</p> <p><img src="/assets/img/adaptive_sampling.png" alt="transformer" class="l-body rounded z-depth-1 center" width="80%"/></p> <div class="l-gutter caption"> <p><strong>Figure 1.</strong> Classification of adaptive sampling techniques: Where adaptive sampling and active learning meet.</p> </div> <h2 id="learning-and-infill-criteria">Learning and infill criteria</h2> <p>The strong synergy between AL and BO is rooted in the substantial analogy between the learning criteria that drive the AL procedure and the infill criteria that characterize the BO scheme.</p> <h3 id="learning-criteria">Learning criteria</h3> <p>Learning criteria establish a metric for quantifying the gains of all the possible learner decisions, and prescribe an optimal decision based in information acquired from the surrogate model. In AL, there are 3 essential learning criteria<d-cite key="he2014active"></d-cite>:</p> <ol> <li><strong>Informativeness:</strong> The sampling policy is driven by the goal of acquiring the <em>most informative samples</em>, i.e., the ones that are expected to contribute the maximum information.</li> <li><strong>Representativeness:</strong> The sampling policy aims to select <em>samples that are representative</em> of the target domain, exploiting the structure of the problem to direct queries to locations</li> <li><strong>Diversity:</strong> The sampling policy seeks to select <em>samples that are diverse</em>, i.e., well-spread across the domain, preventing the concentration of queries in small local regions.</li> </ol> <p><img src="/assets/img/learning_criteria.png" alt="transformer" class="l-body rounded z-depth-1 center" width="100%"/></p> <div class="l-gutter caption"> <p><strong>Figure 2.</strong> Illustration of the three learning criteria in watering optimization problem: (a) informativeness, (b) representativeness, and (c) diversity.</p> </div> <h3 id="infill-criteria">Infill criteria</h3> <p>On the other hand, the infill criteria in BO provides a measure of the information gain that would result from sampling at a particular location. The most common infill criteria are<d-cite key="garnett2023bayesian"></d-cite>:</p> <ol> <li><strong>Global exploration:</strong> This criterion focuses on choosing samples in regions of <em>high predictive uncertainty</em>, enhancing global awareness of the search space. However, this approach may not direct resources optimally towards the specific goal.</li> <li><strong>Local exploitation:</strong> This criterion prioritizes choosing samples in regions with <em>high predictive mean</em>, focusing the search on promising areas. Yet, it may result in less accurate knowledge of the overall objective function distribution.</li> </ol> <aside class="l-body box-important"> <p>Overall, we can observe a strong correspondence between the learning criteria in AL and the infill criteria in BO:</p> <ul> <li><strong>The “informativeness” criterion in AL aligns with the “local exploitation” criterion in BO</strong>, as both aim to maximize the information gain.</li> <li>Similarly, <strong>the “representativeness” and “diversity” criteria in AL correspond to the “global exploration” criterion in BO</strong>, as they seek to ensure that the sampling process is well-distributed across the domain.</li> </ul> </aside> <h2 id="takeaways">Takeaways</h2> <p>BO and AL have traditionally been viewed as distinct fields with separate goals and methodologies. However, this paper provides a unified perspective that highlights the shared principles underlying both fields. By recognizing the synergy between BO and AL, we can leverage the strengths of each field to develop more powerful and efficient learning algorithms.</p>]]></content><author><name>Richard Cornelius Suwandi</name></author><category term="paper-summary"/><category term="bayesian-optimization"/><category term="active-learning"/><summary type="html"><![CDATA[A unified perspective of Bayesian optimization and active learning]]></summary></entry><entry><title type="html">Gaussian Process in Action</title><link href="https://richardcsuwandi.github.io/blog/2021/gp-in-action/" rel="alternate" type="text/html" title="Gaussian Process in Action"/><published>2021-09-20T17:00:00+00:00</published><updated>2021-09-20T17:00:00+00:00</updated><id>https://richardcsuwandi.github.io/blog/2021/gp-in-action</id><content type="html" xml:base="https://richardcsuwandi.github.io/blog/2021/gp-in-action/"><![CDATA[<p>Gaussian processes (GPs) are a powerful yet often underappreciated model in machine learning. As a non-parametric and Bayesian approach, GPs are particularly effective for supervised learning tasks such as regression and classification. Compared to other models, GPs offer several practical advantages:</p> <ul> <li>They perform well even with small datasets.</li> <li>They provide uncertainty quantification for predictions.</li> </ul> <p>In this tutorial, we will implement GP regression using GPyTorch, a GP library built on <a href="https://pytorch.org">PyTorch</a> that is designed for creating scalable and flexible GP models. To learn more about GPyTorch, I recommend visiting their <a href="https://gpytorch.ai/">official website</a>.</p> <aside class="l-body box-warning"> <p><strong>Note:</strong> If you want to follow along with this tutorial, you can find the notebook <a href="https://github.com/richardcsuwandi/gp/blob/main/GP%20Regression%20using%20GPyTorch.ipynb">here</a>.</p> </aside> <h2 id="setup">Setup</h2> <p>Before we begin, we need to install the <code class="language-plaintext highlighter-rouge">gpytorch</code> library. You can do this using either <code class="language-plaintext highlighter-rouge">pip</code> or <code class="language-plaintext highlighter-rouge">conda</code> with the following commands:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>gpytorch <span class="c"># using pip</span>
conda <span class="nb">install </span>gpytorch <span class="nt">-c</span> gpytorch <span class="c"># using conda</span>
</code></pre></div></div> <h2 id="generating-the-data">Generating the data</h2> <p>Next, we will generate training data for our model by modeling the following function:</p> \[y = \sin{(2\pi x)} + \epsilon, \epsilon \sim \mathcal{N}(0,0.04)\] <p>We will evaluate this function at 15 equally spaced points in the interval \([0,1]\). The generated training data is illustrated in the following plot:</p> <p><img src="/assets/img/gpr_data.png" alt="transformer" class="l-body rounded z-depth-1 center" width="70%"/></p> <div class="l-gutter caption"> <p><strong>Figure 1.</strong> The generated training data by evaluating the true function on 15 equally-spaced points from \([0,1]\).</p> </div> <h2 id="building-the-model">Building the model</h2> <p>Now that we have our training data, we can start building our GP model. GPyTorch provides a flexible framework for constructing GP models, similar to building neural networks in standard PyTorch. For most GP regression models, you will need to create the following components:</p> <aside class="l-body box-note"> <ul> <li><strong>A GP model:</strong> For exact (non-variational) GP models, use <code class="language-plaintext highlighter-rouge">gpytorch.models.ExactGP</code>.</li> <li><strong>A likelihood function:</strong> For GP regression, we typically use <code class="language-plaintext highlighter-rouge">gpytorch.likelihoods.GaussianLikelihood</code>.</li> <li><strong>A mean function:</strong> This serves as the prior mean of the GP. If you’re unsure which mean function to use, <code class="language-plaintext highlighter-rouge">gpytorch.means.ConstantMean</code> is a good starting point.</li> <li><strong>A kernel function:</strong> This defines the prior covariance of the GP. For this tutorial, we will use the <a href="https://arxiv.org/pdf/1302.4245.pdf">spectral mixture (SM)</a> kernel (<code class="language-plaintext highlighter-rouge">gpytorch.kernels.SpectralMixtureKernel</code>).</li> <li><strong>A multivariate normal distribution:</strong> Represented by <code class="language-plaintext highlighter-rouge">gpytorch.distributions.MultivariateNormal</code>.</li> </ul> </aside> <p>We can build our GP model by assembling these components as follows:</p> <details><summary>Show code</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">SpectralMixtureGP</span><span class="p">(</span><span class="n">gpytorch</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="n">ExactGP</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">SpectralMixtureGP</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">gpytorch</span><span class="p">.</span><span class="n">means</span><span class="p">.</span><span class="nc">ConstantMean</span><span class="p">()</span> <span class="c1"># Construct the mean function
</span>        <span class="n">self</span><span class="p">.</span><span class="n">cov</span> <span class="o">=</span> <span class="n">gpytorch</span><span class="p">.</span><span class="n">kernels</span><span class="p">.</span><span class="nc">SpectralMixtureKernel</span><span class="p">(</span><span class="n">num_mixtures</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span> <span class="c1"># Construct the kernel function
</span>        <span class="n">self</span><span class="p">.</span><span class="n">cov</span><span class="p">.</span><span class="nf">initialize_from_data</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="c1"># Initialize the hyperparameters from data
</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Evaluate the mean and kernel function at x
</span>        <span class="n">mean_x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">cov_x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">cov</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># Return the multivariate normal distribution using the evaluated mean and kernel function
</span>        <span class="k">return</span> <span class="n">gpytorch</span><span class="p">.</span><span class="n">distributions</span><span class="p">.</span><span class="nc">MultivariateNormal</span><span class="p">(</span><span class="n">mean_x</span><span class="p">,</span> <span class="n">cov_x</span><span class="p">)</span> 

<span class="c1"># Initialize the likelihood and model
</span><span class="n">likelihood</span> <span class="o">=</span> <span class="n">gpytorch</span><span class="p">.</span><span class="n">likelihoods</span><span class="p">.</span><span class="nc">GaussianLikelihood</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="nc">SpectralMixtureGP</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">)</span>
</code></pre></div></div> </details> <p>Here’s a breakdown of the code:</p> <aside class="l-body box-important"> <ul> <li>The GP model consists of two main components: the <code class="language-plaintext highlighter-rouge">__init__</code> and <code class="language-plaintext highlighter-rouge">forward</code> methods.</li> <li>The <code class="language-plaintext highlighter-rouge">__init__</code> method initializes the model with training data and a likelihood, constructing necessary objects like the mean and kernel functions.</li> <li>The forward method takes the input data <code class="language-plaintext highlighter-rouge">x</code> and returns a multivariate normal distribution based on the evaluated mean and covariance.</li> <li>We initialize the likelihood function for the GP model using the Gaussian likelihood, which assumes a homoskedastic noise model (i.e., uniform noise across inputs).</li> </ul> </aside> <h2 id="training-the-model">Training the model</h2> <p>With the model built, we can now train it to find the optimal hyperparameters. Training a GP model in GPyTorch is akin to training a neural network in standard PyTorch. The training loop involves the following steps:</p> <ul> <li>Setting all parameter gradients to zero.</li> <li>Calling the model to compute the loss.</li> <li>Backpropagating the loss to compute gradients.</li> <li>Taking a step with the optimizer.</li> </ul> <aside class="l-body box-warning"> <p><strong>Remark:</strong> By creating a custom training loop, we gain greater flexibility in training, such as saving parameters at each step or using different learning rates for different parameters.</p> </aside> <p>Here’s the code for the training loop:</p> <details><summary>Show code</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Put the model into training mode
</span><span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
<span class="n">likelihood</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>

<span class="c1"># Use the Adam optimizer, with learning rate set to 0.1
</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="c1"># Use the negative marginal log-likelihood as the loss function
</span><span class="n">mll</span> <span class="o">=</span> <span class="n">gpytorch</span><span class="p">.</span><span class="n">mlls</span><span class="p">.</span><span class="nc">ExactMarginalLogLikelihood</span><span class="p">(</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>

<span class="c1"># Set the number of training iterations
</span><span class="n">n_iter</span> <span class="o">=</span> <span class="mi">50</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_iter</span><span class="p">):</span>
    <span class="c1"># Set the gradients from previous iteration to zero
</span>    <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
    <span class="c1"># Output from model
</span>    <span class="n">output</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
    <span class="c1"># Compute loss and backprop gradients
</span>    <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="nf">mll</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Iter %d/%d - Loss: %.3f</span><span class="sh">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_iter</span><span class="p">,</span> <span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()))</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
</code></pre></div></div> </details> <p>In this code, we first set our model to training mode. Then, we define the loss function and optimizer to use during training. We use the negative marginal log-likelihood as the loss and Adam as the optimizer, running the loop for 50 iterations.</p> <h2 id="making-predictions">Making predictions</h2> <p>Finally, we can make predictions with the trained model. The routine for evaluating the model and generating predictions is as follows:</p> <details><summary>Show code</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># The test data is 50 equally-spaced points from [0,5]
</span><span class="n">x_test</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>

<span class="c1"># Put the model into evaluation mode
</span><span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
<span class="n">likelihood</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>

<span class="c1"># The gpytorch.settings.fast_pred_var flag activates LOVE (for fast variances)
# See https://arxiv.org/abs/1803.06058
</span><span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">(),</span> <span class="n">gpytorch</span><span class="p">.</span><span class="n">settings</span><span class="p">.</span><span class="nf">fast_pred_var</span><span class="p">():</span>
    <span class="c1"># Obtain the predictive mean and covariance matrix
</span>    <span class="n">f_preds</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
    <span class="n">f_mean</span> <span class="o">=</span> <span class="n">f_preds</span><span class="p">.</span><span class="n">mean</span>
    <span class="n">f_cov</span> <span class="o">=</span> <span class="n">f_preds</span><span class="p">.</span><span class="n">covariance_matrix</span>

    <span class="c1"># Make predictions by feeding model through likelihood
</span>    <span class="n">observed_pred</span> <span class="o">=</span> <span class="nf">likelihood</span><span class="p">(</span><span class="nf">model</span><span class="p">(</span><span class="n">x_test</span><span class="p">))</span>

    <span class="c1"># Initialize plot
</span>    <span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="c1"># Get upper and lower confidence bounds
</span>    <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span> <span class="o">=</span> <span class="n">observed_pred</span><span class="p">.</span><span class="nf">confidence_region</span><span class="p">()</span>
    <span class="c1"># Plot training data as black stars
</span>    <span class="n">ax</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x_train</span><span class="p">.</span><span class="nf">numpy</span><span class="p">(),</span> <span class="n">y_train</span><span class="p">.</span><span class="nf">numpy</span><span class="p">(),</span> <span class="sh">'</span><span class="s">k*</span><span class="sh">'</span><span class="p">)</span>
    <span class="c1"># Plot predictive means as blue line
</span>    <span class="n">ax</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x_test</span><span class="p">.</span><span class="nf">numpy</span><span class="p">(),</span> <span class="n">observed_pred</span><span class="p">.</span><span class="n">mean</span><span class="p">.</span><span class="nf">numpy</span><span class="p">(),</span> <span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">)</span>
    <span class="c1"># Shade between the lower and upper confidence bounds
</span>    <span class="n">ax</span><span class="p">.</span><span class="nf">fill_between</span><span class="p">(</span><span class="n">x_test</span><span class="p">.</span><span class="nf">numpy</span><span class="p">(),</span> <span class="n">lower</span><span class="p">.</span><span class="nf">numpy</span><span class="p">(),</span> <span class="n">upper</span><span class="p">.</span><span class="nf">numpy</span><span class="p">(),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">set_ylim</span><span class="p">([</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">legend</span><span class="p">([</span><span class="sh">'</span><span class="s">Observed Data</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Mean</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Confidence</span><span class="sh">'</span><span class="p">])</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> </details> <p>The above code performs several things:</p> <aside class="l-body box-important"> <ul> <li>It generates test data using 50 equally spaced points from \([0, 5]\).</li> <li>The model is set to evaluation mode, and we utilize <code class="language-plaintext highlighter-rouge">gpytorch.settings.fast_pred_var()</code> for faster predictive distributions.</li> <li>The trained GP model returns a MultivariateNormal distribution containing the posterior mean and covariance, from which we extract the predictive mean and covariance matrix.</li> <li>Finally, we plot the mean and confidence region of the fitted GP model. The <code class="language-plaintext highlighter-rouge">confidence_region()</code> method provides the upper and lower bounds, representing two standard deviations above and below the mean.</li> </ul> </aside> <p>The resulting plot is shown below:</p> <p><img src="/assets/img/gpr_pred.png" alt="transformer" class="l-body rounded z-depth-1 center" width="70%"/></p> <div class="l-gutter caption"> <p><strong>Figure 2.</strong> Plot of the fitted GP model given by the mean (blue line) and confidence region (shaded area). The observed data (black stars) is also plotted in the figure.</p> </div> <p>In this plot, the black stars (★) represent the training (observed) data, while the blue line and shaded area (🟦) indicate the mean and confidence bounds, respectively. Notice how the uncertainty decreases near the observed points. If we added more data points, we would see the mean function adjust to pass through them, further reducing uncertainty close to the observations.</p> <h2 id="takeaways">Takeaways</h2> <p>In this tutorial, we learned how to build a GP model using GPyTorch. There are many additional <a href="https://docs.gpytorch.ai/en/latest/">features</a> in GPyTorch that I did not cover here. I hope this tutorial serves as a solid foundation for you to explore GPyTorch and Gaussian processes further.</p>]]></content><author><name>Richard Cornelius Suwandi</name></author><category term="tutorial"/><category term="gaussian-process"/><category term="machine-learning"/><summary type="html"><![CDATA[Building a Gaussian process model with GPyTorch]]></summary></entry></feed>